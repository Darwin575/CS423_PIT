{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34ef292",
   "metadata": {},
   "source": [
    "# PIT - CS423 (Intelligent Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5924325",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using VADER and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe430cc1",
   "metadata": {},
   "source": [
    "__Submitted By: Lariosa, Gerald Darwin,__\n",
    "\n",
    "__Malacaste, Febby Kim__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfa0ac",
   "metadata": {},
   "source": [
    "_Submitted At: May 23, 2025_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0ed8d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# NLP preprocessing libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# For exporting the model\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f11523",
   "metadata": {},
   "source": [
    "## Load the Dataset and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afa759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (1000000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Your submission has been automatically removed...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww</td>\n",
       "      <td>Dont squeeze her with you massive hand, you me...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming</td>\n",
       "      <td>It's pretty well known and it was a paid produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>You know we have laws against that currently c...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>Yes, there is a difference between gentle supp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit                                               body  \\\n",
       "0  gameofthrones  Your submission has been automatically removed...   \n",
       "1            aww  Dont squeeze her with you massive hand, you me...   \n",
       "2         gaming  It's pretty well known and it was a paid produ...   \n",
       "3           news  You know we have laws against that currently c...   \n",
       "4       politics  Yes, there is a difference between gentle supp...   \n",
       "\n",
       "   controversiality  score  \n",
       "0                 0      1  \n",
       "1                 0     19  \n",
       "2                 0      3  \n",
       "3                 0     10  \n",
       "4                 0      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count    Dtype \n",
      "---  ------            --------------    ----- \n",
      " 0   subreddit         1000000 non-null  object\n",
      " 1   body              1000000 non-null  object\n",
      " 2   controversiality  1000000 non-null  int64 \n",
      " 3   score             1000000 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 30.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "df = pd.read_csv('kaggle_RC_2019-05.csv')\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "display(df.head())\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f05009",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Clean Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa04482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping null 'body' entries: (1000000, 4)\n",
      "After removing duplicate comments: (971729, 4)\n",
      "After filtering out very short comments: (971729, 5)\n",
      "After removing removed/deleted comments: (971729, 4)\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove rows with null values in the 'body' column\n",
    "df = df.dropna(subset=['body'])\n",
    "print(\"After dropping null 'body' entries:\", df.shape)\n",
    "\n",
    "# 2. Remove duplicate comments (using the 'body' column)\n",
    "df = df.drop_duplicates(subset=['body'])\n",
    "print(\"After removing duplicate comments:\", df.shape)\n",
    "\n",
    "# 3. Remove very short comments (less than 4 tokens)\n",
    "df['token_count'] = df['body'].apply(lambda x: len(x.split()))\n",
    "df = df[df['token_count'] >= 4]\n",
    "print(\"After filtering out very short comments:\", df.shape)\n",
    "df = df.drop(columns='token_count')\n",
    "\n",
    "# 4. Remove comments that are “[removed]” or “[deleted]”\n",
    "df = df[~df['body'].str.lower().isin(['[removed]', '[deleted]'])]\n",
    "print(\"After removing removed/deleted comments:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330f52d",
   "metadata": {},
   "source": [
    "## Define Custom Preprocessing (Tokenizing, Lemmatizing, and Stopword Removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48967612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensifiers preserved:\n",
      " {'very', 'too', 'not', 'so'}\n",
      "\n",
      "Total stopwords originally: 198\n",
      "Total stopwords updated: 194\n"
     ]
    }
   ],
   "source": [
    "# Load the standard English stopwords.\n",
    "default_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Define a set of intensifiers that you want to preserve.\n",
    "intensifiers = {\n",
    "    \"very\", \"really\", \"so\", \"too\", \"extremely\",\n",
    "    \"incredibly\", \"absolutely\", \"completely\",\n",
    "    \"utterly\", \"highly\", \"remarkably\", \"awfully\", \"not\"\n",
    "}\n",
    "\n",
    "# Remove intensifiers from the default stopwords so they are preserved.\n",
    "updated_stopwords = default_stopwords - intensifiers\n",
    "\n",
    "# Print the removed intensifiers (those that remain preserved)\n",
    "print(\"Intensifiers preserved:\\n\", intensifiers.intersection(default_stopwords))\n",
    "print(\"\\nTotal stopwords originally:\", len(default_stopwords))\n",
    "print(\"Total stopwords updated:\", len(updated_stopwords))\n",
    "\n",
    "# Initialize the lemmatizer (we'll use it below)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def custom_analyzer(text):\n",
    "    \"\"\"\n",
    "    Custom analyzer to perform:\n",
    "    - Lowercasing\n",
    "    - Punctuation removal\n",
    "    - Tokenization\n",
    "    - Stopword removal with updated stopwords list (preserving intensifiers)\n",
    "    - Lemmatization\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and non-alphanumeric characters (preserving spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords using updated_stopwords\n",
    "    tokens = [token for token in tokens if token not in updated_stopwords]\n",
    "    \n",
    "    # Apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140ba5c",
   "metadata": {},
   "source": [
    "## Label the Data with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a951ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after VADER labeling (excluding neutrals): (711241, 5)\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def label_sentiment(text):\n",
    "    \"\"\"\n",
    "    Label text as 'positive' if compound score ≥ 0.05,\n",
    "    'negative' if compound score ≤ -0.05 and\n",
    "    returns None for neutral sentiment.\n",
    "    \"\"\"\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply VADER labeling on the original text (to preserve punctuation cues)\n",
    "df['label'] = df['body'].apply(label_sentiment)\n",
    "\n",
    "# Keep only those rows that are clearly positive or negative.\n",
    "df = df[df['label'].notnull()]\n",
    "print(\"Dataset shape after VADER labeling (excluding neutrals):\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4263b6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Your submission has been automatically removed...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww</td>\n",
       "      <td>Dont squeeze her with you massive hand, you me...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaming</td>\n",
       "      <td>It's pretty well known and it was a paid produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>You know we have laws against that currently c...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>Yes, there is a difference between gentle supp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit                                               body  \\\n",
       "0  gameofthrones  Your submission has been automatically removed...   \n",
       "1            aww  Dont squeeze her with you massive hand, you me...   \n",
       "2         gaming  It's pretty well known and it was a paid produ...   \n",
       "3           news  You know we have laws against that currently c...   \n",
       "4       politics  Yes, there is a difference between gentle supp...   \n",
       "\n",
       "   controversiality  score     label  \n",
       "0                 0      1  positive  \n",
       "1                 0     19  positive  \n",
       "2                 0      3  positive  \n",
       "3                 0     10  negative  \n",
       "4                 0      1  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0344c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "positive    406722\n",
      "negative    304519\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433171f",
   "metadata": {},
   "source": [
    "## Splitting Data and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fba1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 568992 | Test size: 142249\n"
     ]
    }
   ],
   "source": [
    "# Using stratification to maintain class balance in train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['body'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"| Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba23a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:533: UserWarning: The parameter 'ngram_range' will not be used since 'analyzer' is callable'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF transformation completed in parallel.\n"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=custom_analyzer, ngram_range=(1, 2))\n",
    "\n",
    "# Enable parallel processing during TF-IDF transformation\n",
    "with parallel_backend('loky', n_jobs=-1):  # 'loky' uses CPU cores\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF transformation completed in parallel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179d92d",
   "metadata": {},
   "source": [
    "## Training multiple classifiers & Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60b7cdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87     60904\n",
      "    positive       0.91      0.89      0.90     81345\n",
      "\n",
      "    accuracy                           0.89    142249\n",
      "   macro avg       0.88      0.89      0.88    142249\n",
      "weighted avg       0.89      0.89      0.89    142249\n",
      "\n",
      "============================================================\n",
      "=== Naive Bayes Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.64      0.72     60904\n",
      "    positive       0.77      0.91      0.83     81345\n",
      "\n",
      "    accuracy                           0.79    142249\n",
      "   macro avg       0.80      0.77      0.78    142249\n",
      "weighted avg       0.80      0.79      0.79    142249\n",
      "\n",
      "============================================================\n",
      "=== Random Forest Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.68      0.70     60904\n",
      "    positive       0.77      0.79      0.78     81345\n",
      "\n",
      "    accuracy                           0.74    142249\n",
      "   macro avg       0.74      0.74      0.74    142249\n",
      "weighted avg       0.74      0.74      0.74    142249\n",
      "\n",
      "============================================================\n",
      "=== SVM Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86     60904\n",
      "    positive       0.89      0.91      0.90     81345\n",
      "\n",
      "    accuracy                           0.88    142249\n",
      "   macro avg       0.88      0.87      0.88    142249\n",
      "weighted avg       0.88      0.88      0.88    142249\n",
      "\n",
      "============================================================\n",
      "Evaluation Metrics Summary:\n",
      "                     Accuracy  Precision    Recall  F1 Score\n",
      "Logistic Regression  0.885482   0.909424  0.888205  0.898689\n",
      "Naive Bayes          0.791099   0.768725  0.907812  0.832499\n",
      "Random Forest        0.744336   0.769327  0.789698  0.779379\n",
      "SVM                  0.878917   0.885190  0.905735  0.895344\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    solver='saga',\n",
    "    penalty='l2',\n",
    "    C=2.5,                      # Increased to 4 for more capacity\n",
    "    max_iter=2000,            # Extended iterations for robust convergence on large datasets\n",
    "    tol=1e-4,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,                # Utilize all cores for faster computation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Reduced complexity for Random Forest to help allocate more time/resources to Logistic Regression\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=8,            \n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=3,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the other classifiers (static configurations)\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": rf,\n",
    "    \"SVM\": LinearSVC(random_state=42)\n",
    "}\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "# Train and evaluate models in parallel using Joblib\n",
    "with parallel_backend('loky', n_jobs=-1): \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_vec, y_train)\n",
    "        y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "        evaluation_results[clf_name] = {\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"Precision\": precision_score(y_test, y_pred, pos_label='positive'),\n",
    "            \"Recall\": recall_score(y_test, y_pred, pos_label='positive'),\n",
    "            \"F1 Score\": f1_score(y_test, y_pred, pos_label='positive')\n",
    "        }\n",
    "\n",
    "        print(f\"=== {clf_name} Classification Report ===\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "eval_df = pd.DataFrame(evaluation_results).T\n",
    "print(\"Evaluation Metrics Summary:\")\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04b4c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Selected: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Select the best model based on F1 Score\n",
    "best_model_name = max(evaluation_results, key=lambda key: evaluation_results[key][\"F1 Score\"])\n",
    "best_model = classifiers[best_model_name]\n",
    "\n",
    "print(\"Best Model Selected:\", best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf442ae",
   "metadata": {},
   "source": [
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba5f70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved in 'sentiment_best_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# Save the best model using pickle\n",
    "with open(\"sentiment_best_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(\"Best model saved in 'sentiment_best_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "082b32d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved in 'vectorizer.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb\") as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n",
    "    \n",
    "print(\"Vectorizer saved in 'vectorizer.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da6f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
